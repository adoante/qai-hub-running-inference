## Steps
1. `preprocess_images_to_datasets.py`
	- UPDATE BASED ON YOUR AI MODEL and file paths
2. `inference_image_datasets.py`
	- UPDATE BASED ON YOUR AI MODEL and file paths
3. `process_results_datasets.py`
	- UPDATE BASED ON YOUR AI MODEL and file paths
4. `calculate_accuracy.py`
	- UPDATE BASED ON YOUR AI MODEL and file paths

Checkout the helper scripts for splitting the ImageNet images into
50 folders with 1000 images each. I did this so we could test different
size datasets. 10k, 20k, 2k, etc.
